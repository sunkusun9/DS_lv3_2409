{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75850728",
   "metadata": {},
   "source": [
    "# 시험장 환경 정보\n",
    "\n",
    "Python: 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
    "\n",
    "|모듈|버젼|\n",
    "|----|----|\n",
    "|pandas|0.25.1|\n",
    "|numpy|1.18.5|\n",
    "|sklearn|0.21.3|\n",
    "|scipy|1.5.2|\n",
    "|mlxtend|0.15.0.0|\n",
    "|statsmodels|0.11.1|\n",
    "|xgboost|0.8|\n",
    "\n",
    "**강사: 멀티캠퍼스 강선구(sunku0316.kang@multicampus.com, sun9sun9@gmail.com)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2c7a0d-541e-4784-aac1-6aff28495c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.1.1-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.2-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.1-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\student\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\student\\python312\\lib\\site-packages (from statsmodels) (24.1)\n",
      "Collecting matplotlib>=3.0.0 (from mlxtend)\n",
      "  Downloading matplotlib-3.9.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.0.0->mlxtend)\n",
      "  Downloading contourpy-1.3.0-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.0.0->mlxtend)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.0.0->mlxtend)\n",
      "  Downloading fonttools-4.53.1-cp312-cp312-win_amd64.whl.metadata (165 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.0.0->mlxtend)\n",
      "  Downloading kiwisolver-1.4.6-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib>=3.0.0->mlxtend)\n",
      "  Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.0.0->mlxtend)\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: six in c:\\users\\student\\python312\\lib\\site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------  11.3/11.5 MB 54.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 44.9 MB/s eta 0:00:00\n",
      "Downloading numpy-2.1.1-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 56.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 43.8 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl (10.9 MB)\n",
      "   ---------------------------------------- 0.0/10.9 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 8.9/10.9 MB 46.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.9/10.9 MB 42.7 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 11.5/44.5 MB 55.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 23.3/44.5 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 33.3/44.5 MB 51.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.8/44.5 MB 51.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 51.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 51.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 33.7 MB/s eta 0:00:00\n",
      "Downloading statsmodels-0.14.2-cp312-cp312-win_amd64.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   ---------------------------------------  9.7/9.8 MB 67.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.8/9.8 MB 40.9 MB/s eta 0:00:00\n",
      "Downloading mlxtend-0.23.1-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading xgboost-2.1.1-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 11.0/124.9 MB 57.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 20.4/124.9 MB 49.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 31.2/124.9 MB 50.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 37.0/124.9 MB 45.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 38.3/124.9 MB 37.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 48.2/124.9 MB 38.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 49.0/124.9 MB 33.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 51.4/124.9 MB 32.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 54.5/124.9 MB 28.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 62.9/124.9 MB 29.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 70.5/124.9 MB 30.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 75.5/124.9 MB 30.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 76.8/124.9 MB 27.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 85.2/124.9 MB 28.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 95.2/124.9 MB 29.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 97.5/124.9 MB 29.0 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 100.4/124.9 MB 27.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 108.3/124.9 MB 28.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 113.2/124.9 MB 28.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 120.3/124.9 MB 28.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 29.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 29.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 124.9/124.9 MB 26.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading matplotlib-3.9.2-cp312-cp312-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   -------------------------------------- - 7.6/7.8 MB 47.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.8/7.8 MB 32.4 MB/s eta 0:00:00\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Downloading contourpy-1.3.0-cp312-cp312-win_amd64.whl (218 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.53.1-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 20.5 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.6-cp312-cp312-win_amd64.whl (55 kB)\n",
      "Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 48.8 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, pyparsing, pillow, numpy, kiwisolver, joblib, fonttools, cycler, scipy, patsy, pandas, contourpy, xgboost, statsmodels, scikit-learn, matplotlib, mlxtend\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.53.1 joblib-1.4.2 kiwisolver-1.4.6 matplotlib-3.9.2 mlxtend-0.23.1 numpy-2.1.1 pandas-2.2.2 patsy-0.5.6 pillow-10.4.0 pyparsing-3.1.4 pytz-2024.1 scikit-learn-1.5.1 scipy-1.14.1 statsmodels-0.14.2 threadpoolctl-3.5.0 tzdata-2024.1 xgboost-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas numpy scikit-learn scipy statsmodels mlxtend xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b1901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.5 (tags/v3.12.5:ff3bc82, Aug  6 2024, 20:45:27) [MSC v.1940 64 bit (AMD64)]\n",
      "pandas 2.2.2\n",
      "numpy 2.1.1\n",
      "sklearn 1.5.1\n",
      "scipy 1.14.1\n",
      "mlxtend 0.23.1\n",
      "statsmodels 0.14.2\n",
      "xgboost 2.1.1\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels, xgb]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a5207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 모듈 설정\n",
    "# 참고용 차트를 출력하기 위함\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719eb2d",
   "metadata": {},
   "source": [
    "# 문제 개요\n",
    "\n",
    "다음은 폴더블 폰의 힌지에 들어가는 스프링 내구력을 테스트한 실험 결과이다. \n",
    "\n",
    "스프링 측정값과 스프링에 가한 부하 정보와 함께, 테스트 통과/실패 (failure) 결과가 기재되어 있다. \n",
    "\n",
    "개발부서는 테스트 비용을 줄이기 위해 failure 여부를 맞추는 모델을 만들고자 한다.\n",
    "\n",
    "변수명은 보안을 위해 measurement_0과 같이 익명화되었다.\n",
    "\n",
    "데이터 구성\n",
    "\n",
    "학습데이터: train_prob.csv, 21,458 rows, 25 columns\n",
    "\n",
    "테스트데이터: test_prob.csv, 5,112 rows, 24 columns, \n",
    "\n",
    "테스트정답셋: test_prob_ans.csv, 5,112 rows, 1 columns\n",
    "\n",
    "\n",
    "컬럼명\t설명\t타입\n",
    "\n",
    "|변수명|설명|타입|\n",
    "|--|--------------|------|\n",
    "|id|실험 고유 번호|정수형|\n",
    "|product_code|스프링 코드|범주형|\n",
    "|loading|스프링에 가한 부하|실수형|\n",
    "|attribute_0|구성 소재1|범주형|\n",
    "|attribute_1|구성 소재2|범주형|\n",
    "|attribute_2|구성 소재3|정수형|\n",
    "|attribute_3|구성 소재4|정수형|\n",
    "|measurement_0 ~ 17|측정값 0~17|실수형|\n",
    "|failure|성공여부|이진형(0, 1)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d1407",
   "metadata": {},
   "source": [
    "# 전처리(Preprocessing)\n",
    "\n",
    "train_prob.csv를 불러 온다. 이를 basetable이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15ebc269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80.10</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>10.672</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>84.89</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12.448</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>82.43</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>12.715</td>\n",
       "      <td>15.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>101.07</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>12.471</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>188.06</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>10.337</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id product_code  loading attribute_0 attribute_1  attribute_2  attribute_3  \\\n",
       "0   0            A    80.10  material_7  material_8            9            5   \n",
       "1   1            A    84.89  material_7  material_8            9            5   \n",
       "2   2            A    82.43  material_7  material_8            9            5   \n",
       "3   3            A   101.07  material_7  material_8            9            5   \n",
       "4   4            A   188.06  material_7  material_8            9            5   \n",
       "\n",
       "   measurement_0  measurement_1  measurement_2  ...  measurement_9  \\\n",
       "0              7              8              4  ...         10.672   \n",
       "1             14              3              3  ...         12.448   \n",
       "2             12              1              5  ...         12.715   \n",
       "3             13              2              6  ...         12.471   \n",
       "4              9              2              8  ...         10.337   \n",
       "\n",
       "   measurement_10  measurement_11  measurement_12  measurement_13  \\\n",
       "0          15.859          17.594          15.193          15.029   \n",
       "1          17.947          17.915          11.755          14.732   \n",
       "2          15.607             NaN          13.798          16.711   \n",
       "3          16.346          18.377          10.020          15.250   \n",
       "4          17.082          19.932          12.428          16.182   \n",
       "\n",
       "   measurement_14  measurement_15  measurement_16  measurement_17  failure  \n",
       "0             NaN          13.034          14.684         764.100        0  \n",
       "1          15.425          14.395          15.631         682.057        0  \n",
       "2          18.631          14.094          17.946         663.376        0  \n",
       "3          15.562          16.154          17.172         826.282        0  \n",
       "4          12.760          13.153          16.412         579.885        0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21458 entries, 0 to 21457\n",
      "Data columns (total 26 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              21458 non-null  int64  \n",
      " 1   product_code    21458 non-null  object \n",
      " 2   loading         21257 non-null  float64\n",
      " 3   attribute_0     21458 non-null  object \n",
      " 4   attribute_1     21458 non-null  object \n",
      " 5   attribute_2     21458 non-null  int64  \n",
      " 6   attribute_3     21458 non-null  int64  \n",
      " 7   measurement_0   21458 non-null  int64  \n",
      " 8   measurement_1   21458 non-null  int64  \n",
      " 9   measurement_2   21458 non-null  int64  \n",
      " 10  measurement_3   21146 non-null  float64\n",
      " 11  measurement_4   21016 non-null  float64\n",
      " 12  measurement_5   20893 non-null  float64\n",
      " 13  measurement_6   20818 non-null  float64\n",
      " 14  measurement_7   20692 non-null  float64\n",
      " 15  measurement_8   20605 non-null  float64\n",
      " 16  measurement_9   20469 non-null  float64\n",
      " 17  measurement_10  20399 non-null  float64\n",
      " 18  measurement_11  20278 non-null  float64\n",
      " 19  measurement_12  20171 non-null  float64\n",
      " 20  measurement_13  20063 non-null  float64\n",
      " 21  measurement_14  19976 non-null  float64\n",
      " 22  measurement_15  19855 non-null  float64\n",
      " 23  measurement_16  19750 non-null  float64\n",
      " 24  measurement_17  19640 non-null  float64\n",
      " 25  failure         21458 non-null  int64  \n",
      "dtypes: float64(16), int64(7), object(3)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_basetable = pd.read_csv('train_prob.csv')\n",
    "display(df_basetable.head())\n",
    "df_basetable.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f35976",
   "metadata": {},
   "source": [
    "# 단계 1\n",
    "\n",
    "basetable에 measurement_3 ~17 각각의 행이 결측인지 나타내는 파생 변수를 만든다. \n",
    "\n",
    "파생 변수는 이진 형식이고, False는 미결측 True는 결측을 의미한다. \n",
    "\n",
    "파생 변수의 이름은 measurement 번호에 따라 isna_3 ~ 17로 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d8bd808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basetable[['isna_{}'.format(i) for i in range(3, 18)]] = \\\n",
    "    df_basetable[['measurement_{}'.format(i) for i in range(3, 18)]].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffac75be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isna_3</th>\n",
       "      <th>isna_4</th>\n",
       "      <th>isna_5</th>\n",
       "      <th>isna_6</th>\n",
       "      <th>isna_7</th>\n",
       "      <th>isna_8</th>\n",
       "      <th>isna_9</th>\n",
       "      <th>isna_10</th>\n",
       "      <th>isna_11</th>\n",
       "      <th>isna_12</th>\n",
       "      <th>isna_13</th>\n",
       "      <th>isna_14</th>\n",
       "      <th>isna_15</th>\n",
       "      <th>isna_16</th>\n",
       "      <th>isna_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>312</td>\n",
       "      <td>442</td>\n",
       "      <td>565</td>\n",
       "      <td>640</td>\n",
       "      <td>766</td>\n",
       "      <td>853</td>\n",
       "      <td>989</td>\n",
       "      <td>1059</td>\n",
       "      <td>1180</td>\n",
       "      <td>1287</td>\n",
       "      <td>1395</td>\n",
       "      <td>1482</td>\n",
       "      <td>1603</td>\n",
       "      <td>1708</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       isna_3  isna_4  isna_5  isna_6  isna_7  isna_8  isna_9  isna_10  \\\n",
       "count     312     442     565     640     766     853     989     1059   \n",
       "\n",
       "       isna_11  isna_12  isna_13  isna_14  isna_15  isna_16  isna_17  \n",
       "count     1180     1287     1395     1482     1603     1708     1818  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basetable[['isna_{}'.format(i) for i in range(3, 18)]].sum().rename('count').to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173737d",
   "metadata": {},
   "source": [
    "## 단계 2\n",
    "\n",
    "이 과제를 맡은 데이터분석가 지희는 measurement_3~17의 결측치 처리 방안을 고민하던 중, \n",
    "\n",
    "개발부서에서 measurement_17은 product_code별로 failure를 예측하기 위해 \n",
    "\n",
    "measurement_3 ~ measurement_9을 다음과 같이 선형 조합하여 생성한 값이라는 정보를 받았다. \n",
    "\n",
    "$measurement_{17}= \\beta_{0} + \\beta_{3}measurement_{3}+\\beta_{4}measurement_{4}+...+\\beta_{9}measurement_{9}$\n",
    "\n",
    "이는 즉,\n",
    "\n",
    "$measurement_{3}= \\beta'_{0} + \\beta'_{4}measurement_{4}+\\beta'_{5}measurement_{5}+...+\\beta'_{9}measurement_{9} + \\beta'_{17}measurement_{17}$\n",
    "\n",
    "...\n",
    "\n",
    "$measurement_{9}= \\beta''_{0} + \\beta''_{3}measurement_{3}+\\beta''_{4}measurement_{4}+...+\\beta''_{8}measurement_{8}+\\beta''_{17}measurement_{17}$\n",
    "\n",
    "와 같이 measurement_3 ~ measurement_9의 각 변수들도 나머지 변수들과 선형 관계를 지닌다. \n",
    "\n",
    "이 점을 이용하여 대상 변수를 번갈아 가면서 예측 모델을 만들어 최대한 원래 값에 가깝게 복원할 수 있다. \n",
    "\n",
    "이러한 반복적인 결측치 복원 방법을 사내 데이터분석 연구소에 문의 했더니 다음과 같은 가이드를 주었다. \n",
    "\n",
    "> sklearn 모듈에 아직은 실험 단계이지만, 비슷한 경우에 문제 없이 사용했던 사례가 있어 의견을 드립니다. \n",
    "\n",
    "> from sklearn.experimental import enable_iterative_imputer 구문을 사용하여 실험 단계인 모듈을 활성화하고, \n",
    "\n",
    "> sklearn.impute.IterativeImputer를 사용한다면 원하는 결과를 얻을 수 있습니다.\n",
    "\n",
    "가이드의 내용을 참조하여 basetable의 measurement_3~9와 measurement_17 결측치를 복원하라.\n",
    "\n",
    "\n",
    "입력 변수] measurement_3 ~ 9, measurement_17 (입력 변수 순서에 유의)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.experimental.enable_iterative_imputer\n",
    "\n",
    "sklearn.impute.IterativeImputer, random_state=123\n",
    "\n",
    "sklearn.linear_model.LinearRegression\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a94de17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 1: 반복문\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "imp = IterativeImputer(\n",
    "    estimator = LinearRegression(fit_intercept=True),\n",
    "    random_state=123\n",
    ")\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "for i in df_basetable['product_code'].unique():\n",
    "    b_idx = df_basetable['product_code'] == i\n",
    "    df_basetable.loc[b_idx, X_imp] = imp.fit_transform(df_basetable.loc[b_idx, X_imp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "441f9049",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "incompatible index of inserted column with frame index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\frame.py:12687\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  12686\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 12687\u001b[0m     reindexed_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m  12688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m  12689\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\series.py:5153\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5136\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   5137\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m   5138\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5151\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m-> 5153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\generic.py:5610\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5609\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5611\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m   5612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\generic.py:5633\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5632\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5633\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   5635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5637\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4433\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4431\u001b[0m             indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n\u001b[1;32m-> 4433\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_reindex_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target, indexer\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2717\u001b[0m, in \u001b[0;36mMultiIndex._wrap_reindex_result\u001b[1;34m(self, target, indexer, preserve_names)\u001b[0m\n\u001b[0;32m   2716\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2717\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[43mMultiIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tuples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   2719\u001b[0m     \u001b[38;5;66;03m# not all tuples, see test_constructor_dict_multiindex_reindex_flat\u001b[39;00m\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:222\u001b[0m, in \u001b[0;36mnames_compat.<locals>.new_meth\u001b[1;34m(self_or_cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_or_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:617\u001b[0m, in \u001b[0;36mMultiIndex.from_tuples\u001b[1;34m(cls, tuples, sortorder, names)\u001b[0m\n\u001b[0;32m    615\u001b[0m         tuples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(tuples\u001b[38;5;241m.\u001b[39m_values)\n\u001b[1;32m--> 617\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuples_to_object_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuples\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tuples, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mlib.pyx:3029\u001b[0m, in \u001b[0;36mpandas._libs.lib.tuples_to_object_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'Python object' but got 'long long'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 13\u001b[0m\n\u001b[0;32m      7\u001b[0m imp \u001b[38;5;241m=\u001b[39m IterativeImputer(\n\u001b[0;32m      8\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m LinearRegression(fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      9\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m X_imp \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeasurement_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeasurement_17\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdf_basetable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_imp\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m df_basetable\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_code\u001b[39m\u001b[38;5;124m'\u001b[39m)[X_imp]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mDataFrame(imp\u001b[38;5;241m.\u001b[39mfit_transform(x), index\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mX_imp)\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\frame.py:4299\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[0;32m   4298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[1;32m-> 4299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   4301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\frame.py:4343\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4341\u001b[0m     check_key_length(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, key, value)\n\u001b[0;32m   4342\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m-> 4343\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk1\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value[k2]\n\u001b[0;32m   4345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(value):\n\u001b[0;32m   4346\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m key:\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4530\u001b[0m     ):\n\u001b[0;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\frame.py:5263\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Series):\n\u001b[0;32m   5262\u001b[0m         value \u001b[38;5;241m=\u001b[39m Series(value)\n\u001b[1;32m-> 5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reindex_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m   5266\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\python312\\Lib\\site-packages\\pandas\\core\\frame.py:12694\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  12690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m  12691\u001b[0m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n\u001b[0;32m  12692\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m> 12694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m  12695\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible index of inserted column with frame index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  12696\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m  12697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reindexed_value, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: incompatible index of inserted column with frame index"
     ]
    }
   ],
   "source": [
    "# 방법 2: groupby ~ apply ~ fit_transform\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "imp = IterativeImputer(\n",
    "    estimator = LinearRegression(fit_intercept=True),\n",
    "    random_state=123\n",
    ")\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "\n",
    "df_basetable[X_imp] = df_basetable.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(imp.fit_transform(x), index=x.index, columns=X_imp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf960f85-0830-4c1b-8c7e-28630a7cecc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>measurement_5</th>\n",
       "      <th>measurement_6</th>\n",
       "      <th>measurement_7</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.040</td>\n",
       "      <td>12.518000</td>\n",
       "      <td>15.748</td>\n",
       "      <td>19.292</td>\n",
       "      <td>11.739</td>\n",
       "      <td>20.155</td>\n",
       "      <td>10.672000</td>\n",
       "      <td>764.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.213</td>\n",
       "      <td>11.540000</td>\n",
       "      <td>17.717</td>\n",
       "      <td>17.893</td>\n",
       "      <td>12.748</td>\n",
       "      <td>17.889</td>\n",
       "      <td>12.448000</td>\n",
       "      <td>682.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.057</td>\n",
       "      <td>11.652000</td>\n",
       "      <td>16.738</td>\n",
       "      <td>18.240</td>\n",
       "      <td>12.718</td>\n",
       "      <td>18.288</td>\n",
       "      <td>12.715000</td>\n",
       "      <td>663.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.295</td>\n",
       "      <td>11.188000</td>\n",
       "      <td>18.576</td>\n",
       "      <td>18.339</td>\n",
       "      <td>12.583</td>\n",
       "      <td>19.060</td>\n",
       "      <td>12.471000</td>\n",
       "      <td>826.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.346</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>16.990</td>\n",
       "      <td>15.746</td>\n",
       "      <td>11.306</td>\n",
       "      <td>18.093</td>\n",
       "      <td>10.337000</td>\n",
       "      <td>579.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21453</th>\n",
       "      <td>16.301</td>\n",
       "      <td>13.259000</td>\n",
       "      <td>18.068</td>\n",
       "      <td>15.505</td>\n",
       "      <td>10.865</td>\n",
       "      <td>19.354</td>\n",
       "      <td>11.738611</td>\n",
       "      <td>729.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21454</th>\n",
       "      <td>17.543</td>\n",
       "      <td>10.696172</td>\n",
       "      <td>17.984</td>\n",
       "      <td>19.078</td>\n",
       "      <td>11.139</td>\n",
       "      <td>19.563</td>\n",
       "      <td>11.242000</td>\n",
       "      <td>853.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21455</th>\n",
       "      <td>15.670</td>\n",
       "      <td>11.535000</td>\n",
       "      <td>16.778</td>\n",
       "      <td>18.385</td>\n",
       "      <td>11.630</td>\n",
       "      <td>19.279</td>\n",
       "      <td>11.407000</td>\n",
       "      <td>750.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21456</th>\n",
       "      <td>18.059</td>\n",
       "      <td>11.284938</td>\n",
       "      <td>16.918</td>\n",
       "      <td>18.101</td>\n",
       "      <td>11.713</td>\n",
       "      <td>19.358</td>\n",
       "      <td>11.392000</td>\n",
       "      <td>730.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21457</th>\n",
       "      <td>18.034</td>\n",
       "      <td>11.431000</td>\n",
       "      <td>16.918</td>\n",
       "      <td>17.129</td>\n",
       "      <td>12.713</td>\n",
       "      <td>18.731</td>\n",
       "      <td>10.611000</td>\n",
       "      <td>602.354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21458 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       measurement_3  measurement_4  measurement_5  measurement_6  \\\n",
       "0             18.040      12.518000         15.748         19.292   \n",
       "1             18.213      11.540000         17.717         17.893   \n",
       "2             18.057      11.652000         16.738         18.240   \n",
       "3             17.295      11.188000         18.576         18.339   \n",
       "4             19.346      12.950000         16.990         15.746   \n",
       "...              ...            ...            ...            ...   \n",
       "21453         16.301      13.259000         18.068         15.505   \n",
       "21454         17.543      10.696172         17.984         19.078   \n",
       "21455         15.670      11.535000         16.778         18.385   \n",
       "21456         18.059      11.284938         16.918         18.101   \n",
       "21457         18.034      11.431000         16.918         17.129   \n",
       "\n",
       "       measurement_7  measurement_8  measurement_9  measurement_17  \n",
       "0             11.739         20.155      10.672000         764.100  \n",
       "1             12.748         17.889      12.448000         682.057  \n",
       "2             12.718         18.288      12.715000         663.376  \n",
       "3             12.583         19.060      12.471000         826.282  \n",
       "4             11.306         18.093      10.337000         579.885  \n",
       "...              ...            ...            ...             ...  \n",
       "21453         10.865         19.354      11.738611         729.131  \n",
       "21454         11.139         19.563      11.242000         853.924  \n",
       "21455         11.630         19.279      11.407000         750.364  \n",
       "21456         11.713         19.358      11.392000         730.156  \n",
       "21457         12.713         18.731      10.611000         602.354  \n",
       "\n",
       "[21458 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basetable.groupby('product_code', group_keys=False)[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(imp.fit_transform(x), index=x.index, columns=X_imp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b20b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2-2: groupby ~ apply ~ fit -> groupby ~ apply ~ transfrom\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def create_imp():\n",
    "    return IterativeImputer(\n",
    "        estimator = LinearRegression(fit_intercept=True),\n",
    "        random_state=123\n",
    "    )\n",
    "\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "s_imp = df_basetable.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: create_imp().fit(x)\n",
    ")\n",
    "\n",
    "df_basetable[X_imp] = df_basetable.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(s_imp[x.name].transform(x), index=x.index, columns=X_imp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25691cd5-0cd0-45a7-b70e-5958c627117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(\n",
    "    estimator = LinearRegression(fit_intercept=True),\n",
    "    random_state=123\n",
    ")\n",
    "s_imp = df_basetable.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: imp.fit(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40e28eba-0194-45e2-8c20-5c03f21aa1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_code\n",
       "A    2156733112080\n",
       "B    2156733112080\n",
       "C    2156733112080\n",
       "E    2156733112080\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_imp.apply(lambda x: id(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95edba8",
   "metadata": {},
   "source": [
    "## 단계 3\n",
    "\n",
    "measurement_10~16까지의 결측치는 모두 product_code별 평균으로 대치한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c8d5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 1: groupby ~ transform\n",
    "X_mean = ['measurement_{}'.format(i) for i in range(10, 17)]\n",
    "df_basetable[X_mean] = df_basetable.groupby('product_code')[X_mean].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ad8e609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594000</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>16.110886</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915000</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425000</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15.607</td>\n",
       "      <td>19.439558</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631000</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377000</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562000</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932000</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760000</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21453</td>\n",
       "      <td>12.177</td>\n",
       "      <td>17.942000</td>\n",
       "      <td>10.112</td>\n",
       "      <td>15.795</td>\n",
       "      <td>18.572000</td>\n",
       "      <td>16.144</td>\n",
       "      <td>16.066552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21454</td>\n",
       "      <td>14.179</td>\n",
       "      <td>20.564000</td>\n",
       "      <td>10.234</td>\n",
       "      <td>14.450</td>\n",
       "      <td>14.322000</td>\n",
       "      <td>13.146</td>\n",
       "      <td>16.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21455</td>\n",
       "      <td>16.437</td>\n",
       "      <td>17.476000</td>\n",
       "      <td>8.668</td>\n",
       "      <td>15.069</td>\n",
       "      <td>16.599000</td>\n",
       "      <td>15.590</td>\n",
       "      <td>14.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21456</td>\n",
       "      <td>17.064</td>\n",
       "      <td>17.814000</td>\n",
       "      <td>14.928</td>\n",
       "      <td>16.273</td>\n",
       "      <td>15.485000</td>\n",
       "      <td>13.624</td>\n",
       "      <td>12.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21457</td>\n",
       "      <td>15.603</td>\n",
       "      <td>19.703000</td>\n",
       "      <td>11.006</td>\n",
       "      <td>15.875</td>\n",
       "      <td>13.366000</td>\n",
       "      <td>16.527</td>\n",
       "      <td>17.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21458 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       measurement_10  measurement_11  measurement_12  measurement_13  \\\n",
       "0              15.859       17.594000          15.193          15.029   \n",
       "1              17.947       17.915000          11.755          14.732   \n",
       "2              15.607       19.439558          13.798          16.711   \n",
       "3              16.346       18.377000          10.020          15.250   \n",
       "4              17.082       19.932000          12.428          16.182   \n",
       "...               ...             ...             ...             ...   \n",
       "21453          12.177       17.942000          10.112          15.795   \n",
       "21454          14.179       20.564000          10.234          14.450   \n",
       "21455          16.437       17.476000           8.668          15.069   \n",
       "21456          17.064       17.814000          14.928          16.273   \n",
       "21457          15.603       19.703000          11.006          15.875   \n",
       "\n",
       "       measurement_14  measurement_15  measurement_16  \n",
       "0           16.110886          13.034       14.684000  \n",
       "1           15.425000          14.395       15.631000  \n",
       "2           18.631000          14.094       17.946000  \n",
       "3           15.562000          16.154       17.172000  \n",
       "4           12.760000          13.153       16.412000  \n",
       "...               ...             ...             ...  \n",
       "21453       18.572000          16.144       16.066552  \n",
       "21454       14.322000          13.146       16.471000  \n",
       "21455       16.599000          15.590       14.065000  \n",
       "21456       15.485000          13.624       12.865000  \n",
       "21457       13.366000          16.527       17.890000  \n",
       "\n",
       "[21458 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법 2-1: groupby ~ apply ~ reset_index\n",
    "df_basetable[X_mean] = \n",
    "    df_basetable.groupby('product_code')[X_mean].apply(lambda x: x.fillna(x.mean())).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29d2b85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594000</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>16.110886</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915000</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425000</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15.607</td>\n",
       "      <td>19.439558</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631000</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377000</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562000</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932000</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760000</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21453</td>\n",
       "      <td>12.177</td>\n",
       "      <td>17.942000</td>\n",
       "      <td>10.112</td>\n",
       "      <td>15.795</td>\n",
       "      <td>18.572000</td>\n",
       "      <td>16.144</td>\n",
       "      <td>16.066552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21454</td>\n",
       "      <td>14.179</td>\n",
       "      <td>20.564000</td>\n",
       "      <td>10.234</td>\n",
       "      <td>14.450</td>\n",
       "      <td>14.322000</td>\n",
       "      <td>13.146</td>\n",
       "      <td>16.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21455</td>\n",
       "      <td>16.437</td>\n",
       "      <td>17.476000</td>\n",
       "      <td>8.668</td>\n",
       "      <td>15.069</td>\n",
       "      <td>16.599000</td>\n",
       "      <td>15.590</td>\n",
       "      <td>14.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21456</td>\n",
       "      <td>17.064</td>\n",
       "      <td>17.814000</td>\n",
       "      <td>14.928</td>\n",
       "      <td>16.273</td>\n",
       "      <td>15.485000</td>\n",
       "      <td>13.624</td>\n",
       "      <td>12.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21457</td>\n",
       "      <td>15.603</td>\n",
       "      <td>19.703000</td>\n",
       "      <td>11.006</td>\n",
       "      <td>15.875</td>\n",
       "      <td>13.366000</td>\n",
       "      <td>16.527</td>\n",
       "      <td>17.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21458 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       measurement_10  measurement_11  measurement_12  measurement_13  \\\n",
       "0              15.859       17.594000          15.193          15.029   \n",
       "1              17.947       17.915000          11.755          14.732   \n",
       "2              15.607       19.439558          13.798          16.711   \n",
       "3              16.346       18.377000          10.020          15.250   \n",
       "4              17.082       19.932000          12.428          16.182   \n",
       "...               ...             ...             ...             ...   \n",
       "21453          12.177       17.942000          10.112          15.795   \n",
       "21454          14.179       20.564000          10.234          14.450   \n",
       "21455          16.437       17.476000           8.668          15.069   \n",
       "21456          17.064       17.814000          14.928          16.273   \n",
       "21457          15.603       19.703000          11.006          15.875   \n",
       "\n",
       "       measurement_14  measurement_15  measurement_16  \n",
       "0           16.110886          13.034       14.684000  \n",
       "1           15.425000          14.395       15.631000  \n",
       "2           18.631000          14.094       17.946000  \n",
       "3           15.562000          16.154       17.172000  \n",
       "4           12.760000          13.153       16.412000  \n",
       "...               ...             ...             ...  \n",
       "21453       18.572000          16.144       16.066552  \n",
       "21454       14.322000          13.146       16.471000  \n",
       "21455       16.599000          15.590       14.065000  \n",
       "21456       15.485000          13.624       12.865000  \n",
       "21457       13.366000          16.527       17.890000  \n",
       "\n",
       "[21458 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법 2-2: groupby ~ apply\n",
    "df_basetable[X_mean] = \n",
    "    df_basetable.groupby('product_code')[X_mean].apply(lambda x: pd.DataFrame(x.fillna(x.mean()), index=x.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62884d7",
   "metadata": {},
   "source": [
    "Hint] 전처리 단계에서 보간 결과를 확인해 보기 위한 각 변수의 평균과 표본표준편차.\n",
    "\n",
    "| |3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|\n",
    "|-|-|-|-|-|-|-|-|--|--|--|--|--|--|--|--|\n",
    "|mean|17.796|11.736|17.131|17.506|11.719|19.022|11.434|16.034|19.194|11.734|15.666|16.033|15.051|16.398|701.768|\n",
    "|std|0.997|0.994|0.994|0.992|0.993|1.005|0.997|1.278|1.579|1.433|1.149|1.461|1.478|1.671|119.180|\n",
    "\n",
    "열의 이름의 숫자는 measurement_ 번호, 값은 소수점 3째 자리까지 반올림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ff22f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>17.796</td>\n",
       "      <td>11.736</td>\n",
       "      <td>17.131</td>\n",
       "      <td>17.506</td>\n",
       "      <td>11.719</td>\n",
       "      <td>19.022</td>\n",
       "      <td>11.434</td>\n",
       "      <td>16.034</td>\n",
       "      <td>19.194</td>\n",
       "      <td>11.734</td>\n",
       "      <td>15.666</td>\n",
       "      <td>16.033</td>\n",
       "      <td>15.051</td>\n",
       "      <td>16.398</td>\n",
       "      <td>701.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.278</td>\n",
       "      <td>1.579</td>\n",
       "      <td>1.433</td>\n",
       "      <td>1.149</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.478</td>\n",
       "      <td>1.671</td>\n",
       "      <td>119.180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           3       4       5       6       7       8       9      10      11  \\\n",
       "mean  17.796  11.736  17.131  17.506  11.719  19.022  11.434  16.034  19.194   \n",
       "std    0.997   0.994   0.994   0.992   0.993   1.005   0.997   1.278   1.579   \n",
       "\n",
       "          12      13      14      15      16       17  \n",
       "mean  11.734  15.666  16.033  15.051  16.398  701.768  \n",
       "std    1.433   1.149   1.461   1.478   1.671  119.180  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basetable[['measurement_{}'.format(i) for i in range(3, 18)]].agg(['mean', 'std']).round(3)\\\n",
    "            .rename(columns=lambda x: x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218dab47",
   "metadata": {},
   "source": [
    "# 문제1\n",
    "\n",
    "(basetable을 사용) measurement_3~16까지 결측 여부가 failure에 영향이 있는지를 파악하고, \n",
    "\n",
    "failure를 분류하는 데 도움이 될 만한 것은 예측 모델의 입력 변수로 사용하고자 한다. \n",
    "\n",
    "이를 위해 전처리 과정에서 뽑아낸 isna_3~16을 활용한다.\n",
    "\n",
    "n이 3부터 16까지, 즉 measurement_3~16까지 다음의 검정을 수행한다. \n",
    "\n",
    "$H_0: P(failure=True|measurement_{n}=Missing)=P(failure=True)$\n",
    "\n",
    "$H_1: P(failure=True|measurement_{n}=Missing) \\neq P(failure=True)$\n",
    "\n",
    "모집단의 $P(failure=True) = 0.2114$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed64b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91304a06",
   "metadata": {},
   "source": [
    "## 단계 1-1\n",
    "\n",
    "우선, measurement_3으로 위 검정을 시행해보자.\n",
    "\n",
    "$H_0: P(failure=True|isna_{3}=True)=0.2114$\n",
    "\n",
    "$H_1: P(failure=True|isna_{3}=True) \\neq 0.2114$\n",
    "\n",
    "으로 바꿀 수 있다.\n",
    "\n",
    "$P(failure=True|isna_{3}=True)$은 표본수가 충분하여 중심극한정리에 의해 정규분포를 따르는 것은 분석가 간에 이견이 없다고 한다. \n",
    "\n",
    "위 검정의 p-value를 구하여 보고 힌트에 주어진 p-value와 비교하여 검정 방법에 문제가 없음을 확인하라.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 에서 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n",
    "\n",
    " Hint] p-value는 0.0037(소수점 다섯째 자리에서 반올림하여 넷째 자리까지 표시)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b98c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91c87c44",
   "metadata": {},
   "source": [
    "## 단계 1-2\n",
    "\n",
    "measuremenet_3을 포함하여 measurement_4 ~ 16까지 위 검정을 반복하고 \n",
    "\n",
    "귀무가설을 기각할 수 있는 경우의 p-value의 합을 A라고 한다. (유의 수준은 5%로 한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49aa12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df03a86a",
   "metadata": {},
   "source": [
    "## 단계 1-3\n",
    "\n",
    "검정 결과 귀무가설을 기각할 수 있는 경우는 총 두 건이다. \n",
    "\n",
    "해당 파생 변수명의 뒷 자리 번호 순으로 na_1, na_2로 파생 변수를 만들어 prob1 데이터셋을 생성하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e8c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c33bbf8c",
   "metadata": {},
   "source": [
    "A의 값을 소수점 넷째 자리에서 반올림하여 셋째 자리까지 출력하시오. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d2d0f",
   "metadata": {},
   "source": [
    "# 문제 2\n",
    "\n",
    "첫째는 스프링 개발 업체들은 실험이 제품 별로 공정하게 진행이 됐는지를 의문을 가지고 있다.\n",
    "\n",
    "product_code에 따라 개발 업체가 다르다. \n",
    "\n",
    "product_code에 따라서 스프링에 가한 부하(loading)를 동일하게 했는지 조사하라.\n",
    "\n",
    "둘째는, attribute_0와 attribute_1은 스프링을 구성하는 주요 소재이다. \n",
    "\n",
    "failure와는 관계가 없음이 이전에 검증되었다. \n",
    "\n",
    "하지만, 이에 대한 재확인 요청을 받아 attribute_0와 attribute_1은 failure와 상관없음을 확인한다.\n",
    "\n",
    "이를 위해 다음 단계를 수행하라.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb314a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfc21275",
   "metadata": {},
   "source": [
    "## 단계 2-1\n",
    "\n",
    "prob1에서 입력 변수 loading에 결측이 없는 행들을 뽑아 prob2 데이터프레임을 만든다.\n",
    "\n",
    "Hint] prob2의 데이터 수는 21,257 이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef461d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ebf527",
   "metadata": {},
   "source": [
    "## 단계 2-2\n",
    "\n",
    "prob2에 loading의 각 행들에 자연 로그 함수를 적용하여 파생 변수 loading_log를 만든다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0152db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea2245b2",
   "metadata": {},
   "source": [
    "## 단계 2-3\n",
    "\n",
    "loading_log가 product_code 각각에 대해서 정규성을 지니고 있는지 확인하고자 한다.\n",
    "\n",
    "이를 위해 product_code 별로 loading_log에 대한 Jarque-Bera로 검정하고, \n",
    "\n",
    "검정 결과 정규성을 부정할 수 없는 경우의 product_code의 수를 B라고 한다.(유의 수준: 5%)\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 에서 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7563df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dce7e5cf",
   "metadata": {},
   "source": [
    "## 단계 2-4\n",
    "\n",
    "loading_log 변수를 product_code로 구분했을 때, \n",
    "\n",
    "등분산성을 보이는지 Bartlett 검정을 통해 확인한다.\n",
    "\n",
    "검정 결과에서 p-value를 C라고 한다.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 에서 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e4897b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b058c6b2",
   "metadata": {},
   "source": [
    "## 단계 2-5\n",
    "\n",
    "product_code에 대한 분산분석(ANOVA)을 통해서 loading_log 평균에 차이가 있는지 검정한다.\n",
    "\n",
    "그 결과 중 p-value를 D라고 한다.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47f9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3c23d2c",
   "metadata": {},
   "source": [
    "## 단계 2-6\n",
    "\n",
    "카이제곱검정을 통해 attribute_0, attribute_1의 결합값이 failure와 연관이 있는지 조사하라. \n",
    "\n",
    "attribute_0, attribute_1의 결합값의 의미 attribute_0=material_7, attribute_1=material_8 이라면, 이 둘의 결합값은\n",
    "matertial_7material_8를 의미한다.\n",
    "\n",
    "(유의 수준 1%) 연관이 있다면 E값은 1 없으면 0으로 한다.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats.chi2_contingency, correction=False\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487a9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af42805f",
   "metadata": {},
   "source": [
    "B + C + D + E의 값을 소수점 셋째 자리에서 반올림하여 둘째 자리까지 출력하시오.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe1afc",
   "metadata": {},
   "source": [
    "# 문제 3\n",
    "\n",
    "로지스틱 회귀모델로 수치형 변수 measurement_0 ~ 17, \n",
    "\n",
    "loading과 이진형인 na_1, na_2 중에서 최적의 성능을 보이는 입력 변수들을 찾고자 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a63c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1ec19e2",
   "metadata": {},
   "source": [
    "## 단계 3-1\n",
    "\n",
    "prob1을 복사하여 prob3을 만든다. loading의 결측치는 loading의 평균으로 대치한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e376a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61eb5594",
   "metadata": {},
   "source": [
    "## 단계 3-2: \n",
    "    \n",
    "prob3를 80%는 학습데이터 prob3_train으로 20%는 테스트데이터 prob3_test로 나눈다. \n",
    "\n",
    "prob3_train의 failure가 1인 비율과 prob3_test의 failure가 1의 비율을 동일하게 한다.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " sklearn.model_selection.train_test_split, random_state=123, \n",
    " \n",
    " train과 test의 failure의 비율은 stratify 매개 변수를 이용하여 맞춘다.\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58d9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7716c3a",
   "metadata": {},
   "source": [
    "## 단계 3-3\n",
    "\n",
    "prob3_train의 수치형 입력 변수 loading, measurement_0 ~ 17을 표준화한다. \n",
    "\n",
    "prob3_train의 표준화 설정으로 prob3_test의 loading, measurement_0 ~ 17에도 적용한다. \n",
    "\n",
    "표준화 처리한 prob3_train과 prob3_test는 문제 4와 문제 5에서 사용한다.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " sklearn.preprocessing 제공 기능 활용, \n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17f958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b20b6ef8",
   "metadata": {},
   "source": [
    "## 단계 3-4\n",
    "    \n",
    "로지스틱 회귀모델을 사용하여 loading, measurement_0~17과 na_1, na_2를 입력 변수로 하여 prob3_train을 학습한다. \n",
    "\n",
    "로지스틱 회귀모델을 prob3_test로 성능을 측정한 값을 A라고 한다.\n",
    "\n",
    "입력 변수: loading, measurement_0~17, na_1, na_2\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " sklearn.linear_model.LogisticRegression, solver='lbfgs', 문제 지시사항 외 Default 값 사용\n",
    " \n",
    " sklearn.metrics.roc_auc_score\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86e3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cba372a",
   "metadata": {},
   "source": [
    "## 단계 3-5\n",
    "\n",
    "loading, measurement_0 ~ 17, na_1, na_2를 후보 입력 변수로 한다. \n",
    "\n",
    "전진 선택법을 사용하여 이 후보 입력 변수 중에서 최적의 성능을 보이는 입력 변수의 조합을 찾는다. \n",
    "\n",
    "전진 선택법의 선택 기준은 prob3_train을 대상으로 5겹 층화교차검증(5-Fold stratified cross validation)을 하고 \n",
    "\n",
    "겹외(OOF, Out-Of Fold) 성능의 평균값으로 한다. 전진 선택 과정에서 선택했던 변수를 제외하지 않는다. \n",
    "\n",
    "입력 변수: 본 단계 요건 참고\n",
    "\n",
    "대상 변수: failure \n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "mlxtend.feature_selection.SequentialFeatureSelector\n",
    "\n",
    "sklearn.linear_model.LogisticRegression, solver='lbfgs'\n",
    "\n",
    "sklearn.metrics.roc_auc_score\n",
    "\n",
    "sklearn.model_selection.StratifiedKFold, random_state=123, shuffle=True\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713233f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e7c6893",
   "metadata": {},
   "source": [
    "## 단계 3-6\n",
    "\n",
    "단계 3-5에서 찾은 최적의 입력 변수 조합으로 로지스틱 회귀모델을 사용하여 prob3_train을 학습하고 \n",
    "\n",
    "prob3_test로 성능을 측정한 값을 B라고 한다.\n",
    "\n",
    "입력 변수: **단계 3-5**에서 도출한 최적의 입력 변수 조합\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수 가이드**\n",
    "\n",
    "sklearn.linear_model.LogisticRegression, solver='lbfgs'\n",
    "\n",
    "sklearn.metrics.roc_auc_score\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96e152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fac40eec",
   "metadata": {},
   "source": [
    "A-B값을 소수점 넷째 자리에서 반올림하여 셋째 자리까지 출력하시오\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed67461",
   "metadata": {},
   "source": [
    "# 문제 4\n",
    "\n",
    "차원 축소 기법을 통한 데이터의 특성과 failure 분류 성능을 높힐 만한 요소를 살펴 본다. \n",
    "\n",
    "첫째로, loading을 제외하고, measurement_0 ~ 17을 입력으로 failure를 대상 변수로 Linear Discrimant Analysis(LDA) 모델을 만든다. \n",
    "\n",
    "True/False 이진 변수인 failure를 분류한다는 점에서 LDA 모델은 measurement_0 ~ 17를 한 개의 경계점으로 \n",
    "\n",
    "failure를 최대한 정확하게 구분하도록 하나의 연속형 변수로 변환한다. \n",
    "\n",
    "스프링의 내구력이 높을 수록 failure 확률이 낮아진다면, \n",
    "\n",
    "측정값 measurement_0 ~ 17의 LDA 변환값은 스프링의 내구력을 나타낸다라고 할 수 있다.\n",
    "\n",
    "실험에서 스프링에 가한 부하(loading)와  LDA 변환값의 상관도를 측정하여, \n",
    "\n",
    "측정값 measurement_0~17 에서 예상되는 내구력이 스프링에 따라 부하(loading)의 반영 정도를 가늠한다.\n",
    "\n",
    "둘째로, PCA를 사용하여 차원 감소로 failure 분류 성능에 얼마나 효과가 있을지 살펴본다.\n",
    "\n",
    "문제3에서 사용했던, 전처리(loading 결측치 처리와 표준화 과정을 거친) 과정을 거친 prob3_train과 prob3_test를 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee8e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3579a749",
   "metadata": {},
   "source": [
    "## 단계 4-1\n",
    "\n",
    "prob3_train에서 measurement_0 ~ 17을 입력으로 failure를 대상 변수로 하여 LDA(Linear Discriminant Analysis) 모델을 학습한다. \n",
    "\n",
    "measurement_0 ~ 17에 대한 prob3_train에서의 LDA의 변환값과 loading과 스피어만 상관도 (spearman correlation)의 p-value를 구하여 A라고 한다.\n",
    "\n",
    "입력 변수] measurement_0 ~ 17 (순서에 유의 하시오)\n",
    "\n",
    "대상 변수] failure\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.discriminant_analysis 제공 기능 활용\n",
    "\n",
    "scipy.stats.spearmanr\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bbc9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e726a4a",
   "metadata": {},
   "source": [
    "## 단계 4-2\n",
    "\n",
    "prob3_train에서 measurement_0 ~ 17을 대상으로 주성분분석(Principal Component Analysis, PCA) 모델을 학습한다. \n",
    "\n",
    "분산 설명율이 높은 순으로 주성분을 변수명을 pca_0 ~ 17하여 prob3_train에 추가하여 prob4_train을 만든다. \n",
    "\n",
    "prob3_test에 prob3_train를 학습했던 PCA 모델로 동일한 방법으로 pca_0 ~17 파생 변수를 추가하여 prob4_test를 만든다.\n",
    "\n",
    "입력 변수] measurement_0 ~ 17 (순서에 유의 하시오)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.decomposition.PCA, random_state=123\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934c155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11d71204",
   "metadata": {},
   "source": [
    "## 단계 4-3\n",
    "\n",
    "초기에 loading을 입력 변수로 하여 prob4_train을 학습하고, prob4_test에 대한 성능을 측정한다.\n",
    "\n",
    "여기에 pca_0에서 pca_17까지 입력 변수를 하나씩 추가 하면서, \n",
    "\n",
    "즉 분산 설명율이 높은 순으로 컴포넌트를 하나씩 추가하여 prob4_train를 학습하고 prob4_test의 성능을 측정 했을 때, \n",
    "\n",
    "최적의 성능을 보인 컴포넌트들의 분산 설명율의 합을 B라고 한다. (만일 없다면 B = 0이다.)\n",
    "\n",
    "입력 변수: 설명 참고\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.linear_model.LogisticRegression, solver=’lbfgs’\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afec2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7a7e38",
   "metadata": {},
   "source": [
    "A + B를 소수점 셋째 자리에서 반올림하여 둘째 자리까지 구하라.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba3524",
   "metadata": {},
   "source": [
    "# 문제 5\n",
    "\n",
    "랜덤포레스트 분류기(Random-Forest Classifier)의 최적의 하이퍼 파라미터(Hyper-Parameter, 초매개변수)를 탐색하고자 한다.\n",
    "\n",
    "문제3에서 사용했던, 전처리(loading 결측치 처리와 표준화 과정을 거친) 과정을 거친 prob3_train과 prob3_test를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e99809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05189b7d",
   "metadata": {},
   "source": [
    "## 단계 5-1\n",
    "\n",
    "sklearn에서 제공하는 랜덤포레스트 분류기(Random-Forest Classifier)의 하이퍼 파라미터 중 \n",
    "\n",
    "n_estimators, max_depth 그리고 min_samples_split의 최적 조합을 탐색한다. \n",
    "\n",
    "탐색 값은 아래에 제공한 하이퍼 파라미터의 모든 조합이다. \n",
    "\n",
    "prob3_train을 대상으로 5-겹 층화교차검증(5-fold stratified cross validation)으로 \n",
    "\n",
    "각각  겹외셋(OOF set, Out-Of-Fold set)의 성능에 대한 평균을 기준으로 하이퍼 파라미터를 선택한다.\n",
    "\n",
    "  - n_estimators: [5, 10, 15]\n",
    "\n",
    "  - max_depth: [5, 6, 7]\n",
    "  \n",
    "  - min_samples_split: [256, 512]\n",
    "\n",
    "Hint] 모든 하이퍼 파라미터의 조합의 수는 18개이다\n",
    "\n",
    "입력 변수: loading, measurement_0 ~ 17, na_1, na_2 (순서에 유의)\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC (area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.ensemble.RandomForestClassifier, random_state=123 \n",
    "\n",
    "itertools.product 필요시 사용\n",
    "\n",
    "sklearn.model_selection.cross_val_score 필요시 사용\n",
    "\n",
    "sklearn.model_selection.StratifiedKFold, random_state=123, shuffle=True\n",
    "\n",
    "sklearn.model_selection.GridSearchCV 필요시 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226741f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eacc40ad",
   "metadata": {},
   "source": [
    "## 단계 5-2\n",
    "\n",
    "단계 5-1에서 구한 최적 하이퍼 파라미터로 설정한 랜덤포레스트 분류기(Random-Forest Classifier)를 사용하여 prob3_train 학습하고, \n",
    "\n",
    "prob3_test로 성능을 측정하여 이 값을 A라고 한다.\n",
    "\n",
    "입력 변수: loading, measurement_0 ~ 17, na_1, na_2 (순서에 유의)\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC (area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.ensemble.RandomForestClassifier, random_state=123 \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebecc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "044dd522",
   "metadata": {},
   "source": [
    "A값을 소수점 넷째 자리에서 반올림하여 3째 자리까지 출력하시오.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c87a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
